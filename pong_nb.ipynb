{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Playing Pong using the DQN algorithm\n",
    "\"\"\"\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "    The policy network for appoximation of the Q function\n",
    "    Model Parameters like in Mnih et al., 2015\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_actions=4, feature_size=3136):\n",
    "        super(DQN, self).__init__()\n",
    "        self.n_actions = n_actions\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc1 = nn.Linear(self.feature_size, 512)\n",
    "        self.fc2 = nn.Linear(512, self.n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \"\"\"\n",
    "    Object for saving the memory\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, experience):\n",
    "        \"\"\"\n",
    "        Saves an experience or just one timepoint\n",
    "        :param experience:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.position >= self.capacity:\n",
    "            self.position = 0\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = experience\n",
    "        self.position += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Take a random batch from the memory\n",
    "        :param batch_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class Person:\n",
    "    \"\"\"\n",
    "    Class with slots to save an experience\n",
    "    \"\"\"\n",
    "    __slots__ = ['state', 'action', 'reward', 'next_state']\n",
    "\n",
    "    def __init__(self, state, action, reward, next_state):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.next_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, epsilon, q_network, n_actions):\n",
    "    \"\"\"\n",
    "    Choose an action given a state, epsilon and the q_network\n",
    "    :param state: \n",
    "    :param epsilon: \n",
    "    :param q_network: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        with torch.no_grad():\n",
    "            return torch.tensor(random.randrange(n_actions))\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax(q_network.forward(state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rl] *",
   "language": "python",
   "name": "conda-env-.conda-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
